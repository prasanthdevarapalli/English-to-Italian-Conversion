{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwLi-x45W6s-",
        "outputId": "80930e7f-0a15-4bc4-bbe1-1e969eba7b5c"
      },
      "source": [
        "!wget http://www.manythings.org/anki/ita-eng.zip\n",
        "!unzip ita-eng.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-10 16:34:57--  http://www.manythings.org/anki/ita-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 172.67.173.198, 104.21.55.222, 2606:4700:3036::ac43:adc6, ...\n",
            "Connecting to www.manythings.org (www.manythings.org)|172.67.173.198|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7567445 (7.2M) [application/zip]\n",
            "Saving to: ‘ita-eng.zip’\n",
            "\n",
            "ita-eng.zip         100%[===================>]   7.22M  6.21MB/s    in 1.2s    \n",
            "\n",
            "2021-02-10 16:34:58 (6.21 MB/s) - ‘ita-eng.zip’ saved [7567445/7567445]\n",
            "\n",
            "Archive:  ita-eng.zip\n",
            "  inflating: ita.txt                 \n",
            "  inflating: _about.txt              \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1fWZ2EhXDkC",
        "outputId": "788cee77-fa77-4b27-bc9e-9f8bf22c503e"
      },
      "source": [
        "!wget https://www.dropbox.com/s/ddkmtqz01jc024u/glove.6B.100d.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-10 16:35:04--  https://www.dropbox.com/s/ddkmtqz01jc024u/glove.6B.100d.txt\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.65.18, 2620:100:6027:18::a27d:4812\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.65.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/ddkmtqz01jc024u/glove.6B.100d.txt [following]\n",
            "--2021-02-10 16:35:04--  https://www.dropbox.com/s/raw/ddkmtqz01jc024u/glove.6B.100d.txt\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc12ef80ec870547e21a5f9c12a6.dl.dropboxusercontent.com/cd/0/inline/BIqmOVLS1-PzgucETQAHNAI9SwUQILLdLg61XuNFH42CMgiWbVLShaJBzhSyNBfqpxZPLdY8dMlcscdPYzg5P3oBSnnENbPcxGnKawLRuCo1VaMb76LsDp8Ok6h_MQgxSPc/file# [following]\n",
            "--2021-02-10 16:35:04--  https://uc12ef80ec870547e21a5f9c12a6.dl.dropboxusercontent.com/cd/0/inline/BIqmOVLS1-PzgucETQAHNAI9SwUQILLdLg61XuNFH42CMgiWbVLShaJBzhSyNBfqpxZPLdY8dMlcscdPYzg5P3oBSnnENbPcxGnKawLRuCo1VaMb76LsDp8Ok6h_MQgxSPc/file\n",
            "Resolving uc12ef80ec870547e21a5f9c12a6.dl.dropboxusercontent.com (uc12ef80ec870547e21a5f9c12a6.dl.dropboxusercontent.com)... 162.125.65.15, 2620:100:6027:15::a27d:480f\n",
            "Connecting to uc12ef80ec870547e21a5f9c12a6.dl.dropboxusercontent.com (uc12ef80ec870547e21a5f9c12a6.dl.dropboxusercontent.com)|162.125.65.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 347116733 (331M) [text/plain]\n",
            "Saving to: ‘glove.6B.100d.txt’\n",
            "\n",
            "glove.6B.100d.txt   100%[===================>] 331.04M  25.0MB/s    in 13s     \n",
            "\n",
            "2021-02-10 16:35:18 (25.8 MB/s) - ‘glove.6B.100d.txt’ saved [347116733/347116733]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQH1WbQqXFc4"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "# import seaborn as sns\n",
        "import pandas as pd\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "9dA9WjV5XIPE",
        "outputId": "068c2d02-5f9f-4e71-c8c6-9c45aa8d6d82"
      },
      "source": [
        "with open('ita.txt', 'r', encoding=\"utf8\") as f:\n",
        "    eng=[]\n",
        "    ita=[]\n",
        "    for i in f.readlines():\n",
        "        eng.append(i.split(\"\\t\")[0])\n",
        "        ita.append(i.split(\"\\t\")[1])\n",
        "data = pd.DataFrame(data=list(zip(eng, ita)), columns=['english','italian'])\n",
        "print(data.shape)\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(345244, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english</th>\n",
              "      <th>italian</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Ciao!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Corri!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Corra!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Correte!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Who?</td>\n",
              "      <td>Chi?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  english   italian\n",
              "0     Hi.     Ciao!\n",
              "1    Run!    Corri!\n",
              "2    Run!    Corra!\n",
              "3    Run!  Correte!\n",
              "4    Who?      Chi?"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "LRpU_wFvXK1z",
        "outputId": "6ded6793-eb6f-42b9-c054-ece1a94990cb"
      },
      "source": [
        "def decontractions(phrase):\n",
        "    \"\"\"decontracted takes text and convert contractions into natural form.\n",
        "     ref: https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python/47091490#47091490\"\"\"\n",
        "    # specific\n",
        "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
        "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
        "    phrase = re.sub(r\"won\\’t\", \"will not\", phrase)\n",
        "    phrase = re.sub(r\"can\\’t\", \"can not\", phrase)\n",
        "\n",
        "    # general\n",
        "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
        "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
        "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
        "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
        "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
        "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
        "\n",
        "    phrase = re.sub(r\"n\\’t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\’re\", \" are\", phrase)\n",
        "    phrase = re.sub(r\"\\’s\", \" is\", phrase)\n",
        "    phrase = re.sub(r\"\\’d\", \" would\", phrase)\n",
        "    phrase = re.sub(r\"\\’ll\", \" will\", phrase)\n",
        "    phrase = re.sub(r\"\\’t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\’ve\", \" have\", phrase)\n",
        "    phrase = re.sub(r\"\\’m\", \" am\", phrase)\n",
        "\n",
        "    return phrase\n",
        "\n",
        "def preprocess(text):\n",
        "    # convert all the text into lower letters\n",
        "    # use this function to remove the contractions: https://gist.github.com/anandborad/d410a49a493b56dace4f814ab5325bbd\n",
        "    # remove all the spacial characters: except space ' '\n",
        "    text = text.lower()\n",
        "    text = decontractions(text)\n",
        "    text = re.sub('[^A-Za-z0-9 ]+', '', text)\n",
        "    return text\n",
        "\n",
        "def preprocess_ita(text):\n",
        "    # convert all the text into lower letters\n",
        "    # remove the words betweent brakets ()\n",
        "    # remove these characters: {'$', ')', '?', '\"', '’', '.',  '°', '!', ';', '/', \"'\", '€', '%', ':', ',', '('}\n",
        "    # replace these spl characters with space: '\\u200b', '\\xa0', '-', '/'\n",
        "    # we have found these characters after observing the data points, feel free to explore more and see if you can do find more\n",
        "    # you are free to do more proprocessing\n",
        "    # note that the model will learn better with better preprocessed data\n",
        "\n",
        "    text = text.lower()\n",
        "    text = decontractions(text)\n",
        "    text = re.sub('[$)\\?\"’.°!;\\'€%:,(/]', '', text)\n",
        "    text = re.sub('\\u200b', ' ', text)\n",
        "    text = re.sub('\\xa0', ' ', text)\n",
        "    text = re.sub('-', ' ', text)\n",
        "    return text\n",
        "\n",
        "\n",
        "data['english'] = data['english'].apply(preprocess)\n",
        "data['italian'] = data['italian'].apply(preprocess_ita)\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english</th>\n",
              "      <th>italian</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hi</td>\n",
              "      <td>ciao</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>run</td>\n",
              "      <td>corri</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>run</td>\n",
              "      <td>corra</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>run</td>\n",
              "      <td>correte</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>who</td>\n",
              "      <td>chi</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  english  italian\n",
              "0      hi     ciao\n",
              "1     run    corri\n",
              "2     run    corra\n",
              "3     run  correte\n",
              "4     who      chi"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WotTJ9DoXNBj"
      },
      "source": [
        "ita_lengths = data['italian'].str.split().apply(len)\n",
        "eng_lengths = data['english'].str.split().apply(len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "z9CgOCeGXPYF",
        "outputId": "75114961-bfa9-44ec-fdde-298d8a38a092"
      },
      "source": [
        "data['italian_len'] = data['italian'].str.split().apply(len)\n",
        "data = data[data['italian_len'] < 20]\n",
        "\n",
        "data['english_len'] = data['english'].str.split().apply(len)\n",
        "data = data[data['english_len'] < 20]\n",
        "\n",
        "data['italian_inp'] = '<start> ' + data['italian'].astype(str)\n",
        "data['italian_out'] = data['italian'].astype(str) + ' <end>'\n",
        "\n",
        "data = data.drop(['italian','italian_len','english_len'], axis=1)\n",
        "# only for the first sentance add a toke <end> so that we will have <end> in tokenizer\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english</th>\n",
              "      <th>italian_inp</th>\n",
              "      <th>italian_out</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hi</td>\n",
              "      <td>&lt;start&gt; ciao</td>\n",
              "      <td>ciao &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>run</td>\n",
              "      <td>&lt;start&gt; corri</td>\n",
              "      <td>corri &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>run</td>\n",
              "      <td>&lt;start&gt; corra</td>\n",
              "      <td>corra &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>run</td>\n",
              "      <td>&lt;start&gt; correte</td>\n",
              "      <td>correte &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>who</td>\n",
              "      <td>&lt;start&gt; chi</td>\n",
              "      <td>chi &lt;end&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  english      italian_inp    italian_out\n",
              "0      hi     <start> ciao     ciao <end>\n",
              "1     run    <start> corri    corri <end>\n",
              "2     run    <start> corra    corra <end>\n",
              "3     run  <start> correte  correte <end>\n",
              "4     who      <start> chi      chi <end>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3fRNUZ5Xepk"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, validation = train_test_split(data, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H83nf6NFXk4o",
        "outputId": "c92b9be6-e3b9-4986-cf51-d534138dd11e"
      },
      "source": [
        "print(train.shape, validation.shape)\n",
        "# for one sentence we will be adding <end> token so that the tokanizer learns the word <end>\n",
        "# with this we can use only one tokenizer for both encoder output and decoder output\n",
        "train.iloc[0]['italian_inp']= str(train.iloc[0]['italian_inp'])+' <end>'\n",
        "train.iloc[0]['italian_out']= str(train.iloc[0]['italian_out'])+' <end>'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(275852, 3) (68964, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "g3cQnn77XvnG",
        "outputId": "436c2bb4-5632-4995-916e-55699c19db75"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english</th>\n",
              "      <th>italian_inp</th>\n",
              "      <th>italian_out</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>209416</th>\n",
              "      <td>i cut my finger with a knife</td>\n",
              "      <td>&lt;start&gt; io mi sono tagliato il dito con un col...</td>\n",
              "      <td>io mi sono tagliato il dito con un coltello &lt;e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97108</th>\n",
              "      <td>why were you so rude</td>\n",
              "      <td>&lt;start&gt; perché eri così maleducato</td>\n",
              "      <td>perché eri così maleducato &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63349</th>\n",
              "      <td>she is my godmother</td>\n",
              "      <td>&lt;start&gt; è la mia madrina</td>\n",
              "      <td>è la mia madrina &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130679</th>\n",
              "      <td>have you registered yet</td>\n",
              "      <td>&lt;start&gt; lei si è già registrato</td>\n",
              "      <td>lei si è già registrato &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64596</th>\n",
              "      <td>tom began shouting</td>\n",
              "      <td>&lt;start&gt; tom iniziò a gridare</td>\n",
              "      <td>tom iniziò a gridare &lt;end&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             english  ...                                        italian_out\n",
              "209416  i cut my finger with a knife  ...  io mi sono tagliato il dito con un coltello <e...\n",
              "97108           why were you so rude  ...                   perché eri così maleducato <end>\n",
              "63349            she is my godmother  ...                             è la mia madrina <end>\n",
              "130679       have you registered yet  ...                      lei si è già registrato <end>\n",
              "64596             tom began shouting  ...                         tom iniziò a gridare <end>\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K62TYJ_fXyEI"
      },
      "source": [
        "tknizer_ita = Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')\n",
        "tknizer_ita.fit_on_texts(train['italian_inp'].values)\n",
        "tknizer_eng = Tokenizer()\n",
        "tknizer_eng.fit_on_texts(train['english'].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQDKWkxSX1GY",
        "outputId": "6ee9c175-1d55-4306-e2f3-811101213f8f"
      },
      "source": [
        "vocab_size_eng=len(tknizer_eng.word_index.keys())\n",
        "print(vocab_size_eng)\n",
        "vocab_size_ita=len(tknizer_ita.word_index.keys())\n",
        "print(vocab_size_ita)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12863\n",
            "26237\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VHH5VBGYTpy",
        "outputId": "667c26a3-b720-459c-a4fa-f3ccd2998329"
      },
      "source": [
        "tknizer_ita.word_index['<start>'], tknizer_ita.word_index['<end>']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 18773)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzA5K-5rYV2D"
      },
      "source": [
        "tf.keras.backend.clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IS4uoCB8YyCH"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    '''\n",
        "    Encoder model -- That takes a input sequence and returns encoder-outputs,encoder_final_state_h,encoder_final_state_c\n",
        "    '''\n",
        "\n",
        "    def __init__(self,inp_vocab_size,embedding_size,lstm_size,input_length):\n",
        "\n",
        "        #Initialize Embedding layer\n",
        "        #Intialize Encoder LSTM layer\n",
        "        super().__init__()\n",
        "        self.vocab_size = inp_vocab_size\n",
        "        self.embedding_dim = embedding_size\n",
        "        self.input_length = input_length\n",
        "        self.lstm_size= lstm_size\n",
        "        self.lstm_output = 0\n",
        "        self.lstm_state_h=0\n",
        "        self.lstm_state_c=0\n",
        "        #self.states = 0\n",
        "    def build(self,input_shape):\n",
        "        self.states = tf.zeros((1024,self.lstm_size)) , tf.zeros((1024,self.lstm_size))\n",
        "        self.embedding = Embedding(input_dim=self.vocab_size, output_dim=self.embedding_dim, input_length=self.input_length,\n",
        "                           mask_zero=True, name=\"embedding_layer_encoder\")\n",
        "        self.lstm = LSTM(self.lstm_size, return_state=True, return_sequences=True, name=\"Encoder_LSTM\")\n",
        "\n",
        "\n",
        "    def call(self,input_sequence,states):\n",
        "        '''\n",
        "          This function takes a sequence input and the initial states of the encoder.\n",
        "          Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to encoder_lstm\n",
        "          returns -- encoder_output, last time step's hidden and cell state\n",
        "        '''\n",
        "        #print(\"ENCODER ==> INPUT SQUENCES SHAPE :\",input_sequence.shape)\n",
        "        input_embedd                           = self.embedding(input_sequence)\n",
        "        #print(\"ENCODER ==> AFTER EMBEDDING THE INPUT SHAPE :\",input_embedd.shape)\n",
        "        self.lstm_output, self.lstm_state_h,self.lstm_state_c = self.lstm(input_embedd)\n",
        "        #print(self.lstm_output.shape)\n",
        "        return self.lstm_output, self.lstm_state_h,self.lstm_state_c\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def initialize_states(self,batch_size):\n",
        "      '''\n",
        "      Given a batch size it will return intial hidden state and intial cell state.\n",
        "      If batch size is 32- Hidden state is zeros of size [32,lstm_units], cell state zeros is of size [32,lstm_units]\n",
        "      '''\n",
        "      return tf.zeros((batch_size,self.lstm_size)) , tf.zeros((batch_size,self.lstm_size))\n",
        "    def get_states(self):\n",
        "      return self.lstm_state_h,self.lstm_state_c"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cd9ZHnpZY07N"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    '''\n",
        "    Encoder model -- That takes a input sequence and returns output sequence\n",
        "    '''\n",
        "\n",
        "    def __init__(self,out_vocab_size,embedding_size,lstm_size,input_length):\n",
        "\n",
        "        #Initialize Embedding layer\n",
        "        #Intialize Decoder LSTM layer\n",
        "        super().__init__()\n",
        "        self.out_vocab_size = out_vocab_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.lstm_size = lstm_size\n",
        "        self.input_length = input_length\n",
        "        self.embedding = Embedding(input_dim=self.out_vocab_size, output_dim=self.embedding_size, input_length=self.input_length,\n",
        "                           mask_zero=True, name=\"embedding_layer_decoder\")\n",
        "        self.lstm = LSTM(self.lstm_size, return_sequences=True, return_state=True, name=\"Decoder_LSTM\")\n",
        "\n",
        "    def call(self,input_sequence,initial_states):\n",
        "        '''\n",
        "          This function takes a sequence input and the initial states of the encoder.\n",
        "          Pass the input_sequence input to the Embedding layer, Pass the embedding layer ouput to decoder_lstm\n",
        "\n",
        "          returns -- decoder_output,decoder_final_state_h,decoder_final_state_c\n",
        "        '''\n",
        "        #print(\"DECODER ==> INPUT SQUENCES SHAPE :\",input_sequence.shape)\n",
        "        target_embedd           = self.embedding(input_sequence)\n",
        "        #print(\"WE ARE INITIALIZING DECODER WITH ENCODER STATES :\",initial_states[0].shape,initial_states[1].shape)\n",
        "        lstm_output, x,y        = self.lstm(target_embedd, initial_state=initial_states)\n",
        "        #print(lstm_output.shape)\n",
        "        return lstm_output,x,y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALyxtiZEY3C-"
      },
      "source": [
        "class Dataset:\n",
        "    def __init__(self, data, tknizer_ita, tknizer_eng, max_len):\n",
        "        self.encoder_inps = data['english'].values\n",
        "        self.decoder_inps = data['italian_inp'].values\n",
        "        self.decoder_outs = data['italian_out'].values\n",
        "        self.tknizer_eng = tknizer_eng\n",
        "        self.tknizer_ita = tknizer_ita\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        self.encoder_seq = tknizer_eng.texts_to_sequences([self.encoder_inps[i]]) # need to pass list of values\n",
        "        self.decoder_inp_seq = tknizer_ita.texts_to_sequences([self.decoder_inps[i]])\n",
        "        self.decoder_out_seq = tknizer_ita.texts_to_sequences([self.decoder_outs[i]])\n",
        "\n",
        "        self.encoder_seq = pad_sequences(self.encoder_seq, maxlen=self.max_len, dtype='int32', padding='post')\n",
        "        self.decoder_inp_seq = pad_sequences(self.decoder_inp_seq, maxlen=self.max_len, dtype='int32', padding='post')\n",
        "        self.decoder_out_seq = pad_sequences(self.decoder_out_seq, maxlen=self.max_len, dtype='int32', padding='post')\n",
        "        return self.encoder_seq, self.decoder_inp_seq, self.decoder_out_seq\n",
        "\n",
        "    def __len__(self): # your model.fit_gen requires this function\n",
        "        return len(self.encoder_inps)\n",
        "\n",
        "\n",
        "class Dataloder(tf.keras.utils.Sequence):\n",
        "    def __init__(self, dataset, batch_size=1):\n",
        "        self.dataset = dataset\n",
        "        self.batch_size = batch_size\n",
        "        self.indexes = np.arange(len(self.dataset.encoder_inps))\n",
        "\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        start = i * self.batch_size\n",
        "        stop = (i + 1) * self.batch_size\n",
        "        data = []\n",
        "        for j in range(start, stop):\n",
        "            data.append(self.dataset[j])\n",
        "\n",
        "        batch = [np.squeeze(np.stack(samples, axis=1), axis=0) for samples in zip(*data)]\n",
        "        # we are creating data like ([italian, english_inp], english_out) these are already converted into seq\n",
        "        return tuple([[batch[0],batch[1]],batch[2]])\n",
        "\n",
        "    def __len__(self):  # your model.fit_gen requires this function\n",
        "        return len(self.indexes) // self.batch_size\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.indexes = np.random.permutation(self.indexes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjxEAbJTY5CM"
      },
      "source": [
        "class Encoder_decoder(tf.keras.Model):\n",
        "\n",
        "    def __init__(self,*params):\n",
        "\n",
        "        #Create encoder object\n",
        "        #Create decoder object\n",
        "        #Intialize Dense layer(out_vocab_size) with activation='softmax'\n",
        "        super().__init__() # https://stackoverflow.com/a/27134600/4084039\n",
        "        self.encoder = Encoder(inp_vocab_size=vocab_size_ita+1, embedding_size=50, input_length=encoder_inputs_length, lstm_size=256)\n",
        "        self.decoder = Decoder(out_vocab_size=vocab_size_eng+1, embedding_size=50, input_length=decoder_inputs_length, lstm_size=256)\n",
        "        self.dense   = Dense(output_vocab_size, activation='softmax')\n",
        "\n",
        "\n",
        "    def call(self,data,batch_size=1024):\n",
        "        '''\n",
        "        A. Pass the input sequence to Encoder layer -- Return encoder_output,encoder_final_state_h,encoder_final_state_c\n",
        "        B. Pass the target sequence to Decoder layer with intial states as encoder_final_state_h,encoder_final_state_C\n",
        "        C. Pass the decoder_outputs into Dense layer\n",
        "\n",
        "\n",
        "        Return decoder_outputs\n",
        "        '''\n",
        "        input,output =data[0], data[1]\n",
        "        #print(data)\n",
        "        #print(\"===========\")\n",
        "        #print(data[0])\n",
        "        #print(\"+==\")\n",
        "        #print(data[0][1])\n",
        "        #print(\"===========\")\n",
        "        #print(input.shape)\n",
        "        #print('output')\n",
        "        #print(type(output))\n",
        "        #encoder_output, encoder_h, encoder_c = self.encoder(input)\n",
        "        states = self.encoder.initialize_states(batch_size)\n",
        "        encoder_output,encoder_final_state_h,encoder_final_state_c = self.encoder(input,states)\n",
        "        decoder_output,_,_ = self.decoder(output,[encoder_final_state_h,encoder_final_state_c])\n",
        "        output = self.dense(decoder_output)\n",
        "        return output\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PV16Jpa-ZF2u",
        "outputId": "b3c23401-6d7d-4de1-8240-5eb8e6d5f776"
      },
      "source": [
        "train_dataset = Dataset(train, tknizer_ita, tknizer_eng, 20)\n",
        "test_dataset  = Dataset(validation, tknizer_ita, tknizer_eng, 20)\n",
        "\n",
        "\n",
        "train_dataloader = Dataloder(train_dataset, batch_size=1024)\n",
        "test_dataloader = Dataloder(test_dataset, batch_size=1024)\n",
        "\n",
        "\n",
        "print(train_dataloader[0][0][0].shape, train_dataloader[0][0][1].shape, train_dataloader[0][1].shape)\n",
        "print(test_dataloader[0][0][0].shape, test_dataloader[0][0][1].shape, test_dataloader[0][1].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1024, 20) (1024, 20) (1024, 20)\n",
            "(1024, 20) (1024, 20) (1024, 20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uT3Q_qSM1VBC"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xk0W-eZYZNdk"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "#Create an object of encoder_decoder Model class,\n",
        "# Compile the model and fit the model\n",
        "encoder_inputs_length = 20\n",
        "decoder_inputs_length = 20\n",
        "lstm_size=64\n",
        "output_vocab_size = vocab_size_eng\n",
        "encoder_decoder = Encoder_decoder(vocab_size_eng, vocab_size_ita,encoder_inputs_length,decoder_inputs_length,output_vocab_size)\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "encoder_decoder.compile(optimizer=optimizer,loss='sparse_categorical_crossentropy')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKiTfWjUZPrv"
      },
      "source": [
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "tensorboard_callback = TensorBoard(log_dir='logs', histogram_freq=1, write_graph=True)\n",
        "model_callback = ModelCheckpoint('model.hdf5',monitor='val_loss',save_best_only=True,mode='min')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Fu9-NYyZVdm"
      },
      "source": [
        "!rm -rf logs/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oKv4Vh2OZXq-",
        "outputId": "1b1e1462-0765-4bf0-b8b1-3ab8f96b1d97"
      },
      "source": [
        "train_steps=train.shape[0]//1024\n",
        "valid_steps=validation.shape[0]//1024\n",
        "batch_size = 1024\n",
        "encoder_decoder.fit(train_dataloader, steps_per_epoch=train_steps, epochs=50, validation_data=train_dataloader,validation_steps=valid_steps,callbacks=[tensorboard_callback,model_callback])\n",
        "encoder_decoder.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-bd240f0021d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mvalid_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mencoder_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensorboard_callback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mencoder_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1062\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1064\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, shuffle, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m    910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001b[0m\n\u001b[1;32m    785\u001b[0m       \u001b[0mconcrete_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpack_x_y_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m       model.distribute_strategy.run(\n\u001b[0;32m--> 787\u001b[0;31m           lambda x: model(x, training=False), args=(concrete_x,))\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1257\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1258\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1259\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2728\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2729\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2730\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2732\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3415\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3416\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3417\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3419\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    570\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    785\u001b[0m       \u001b[0mconcrete_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpack_x_y_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m       model.distribute_strategy.run(\n\u001b[0;32m--> 787\u001b[0;31m           lambda x: model(x, training=False), args=(concrete_x,))\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-69d7b9f455e6>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, data, batch_size)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mencoder_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoder_final_state_h\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoder_final_state_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mdecoder_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencoder_final_state_h\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoder_final_state_c\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-eeb689f8b09b>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, input_sequence, initial_states)\u001b[0m\n\u001b[1;32m     25\u001b[0m         '''\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m#print(\"DECODER ==> INPUT SQUENCES SHAPE :\",input_sequence.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mtarget_embedd\u001b[0m           \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;31m#print(\"WE ARE INITIALIZING DECODER WITH ENCODER STATES :\",initial_states[0].shape,initial_states[1].shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mlstm_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m        \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_embedd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/embeddings.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    194\u001b[0m       \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_lookup_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m       \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_lookup_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype_policy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_dtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype_policy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_dtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m       \u001b[0;31m# Instead of casting the variable as in most layers, cast the output, as\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/embedding_ops.py\u001b[0m in \u001b[0;36membedding_lookup_v2\u001b[0;34m(params, ids, max_norm, name)\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mempty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m   \"\"\"\n\u001b[0;32m--> 394\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0membedding_lookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"div\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/embedding_ops.py\u001b[0m in \u001b[0;36membedding_lookup\u001b[0;34m(params, ids, partition_strategy, name, validate_indices, max_norm)\u001b[0m\n\u001b[1;32m    326\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m       \u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m       transform_fn=None)\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/embedding_ops.py\u001b[0m in \u001b[0;36m_embedding_lookup_and_transform\u001b[0;34m(params, ids, partition_strategy, name, max_norm, transform_fn)\u001b[0m\n\u001b[1;32m    136\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         result = _clip(\n\u001b[0;32m--> 138\u001b[0;31m             array_ops.gather(params[0], ids, name=name), ids, max_norm)\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtransform_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m           \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mgather\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   4811\u001b[0m     \u001b[0;31m# TODO(apassos) find a less bad way of detecting resource variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4812\u001b[0m     \u001b[0;31m# without introducing a circular dependency.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4813\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4814\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4815\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36msparse_read\u001b[0;34m(self, indices, name)\u001b[0m\n\u001b[1;32m    701\u001b[0m       \u001b[0mvariable_accessed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m       value = gen_resource_variable_ops.resource_gather(\n\u001b[0;32m--> 703\u001b[0;31m           self._handle, indices, dtype=self._dtype, name=name)\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariant\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_resource_variable_ops.py\u001b[0m in \u001b[0;36mresource_gather\u001b[0;34m(resource, indices, dtype, batch_dims, validate_indices, name)\u001b[0m\n\u001b[1;32m    547\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6860\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6861\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6862\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6863\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: indices[173,4] = 14638 is not in [0, 12864) [Op:ResourceGather]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQ7jqR-vZjPM",
        "outputId": "435051ab-4717-4ca4-fdee-f0ab5a68baa9"
      },
      "source": [
        "encoder_decoder.fit(train_dataloader, steps_per_epoch=train_steps, epochs=30, validation_data=train_dataloader,validation_steps=valid_steps,callbacks=[tensorboard_callback,model_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "269/269 [==============================] - 44s 165ms/step - loss: 0.0901 - val_loss: 0.0887\n",
            "Epoch 2/30\n",
            "269/269 [==============================] - 44s 164ms/step - loss: 0.0898 - val_loss: 0.0884\n",
            "Epoch 3/30\n",
            "269/269 [==============================] - 45s 165ms/step - loss: 0.0895 - val_loss: 0.0882\n",
            "Epoch 4/30\n",
            "269/269 [==============================] - 44s 165ms/step - loss: 0.0892 - val_loss: 0.0878\n",
            "Epoch 5/30\n",
            "269/269 [==============================] - 44s 164ms/step - loss: 0.0889 - val_loss: 0.0876\n",
            "Epoch 6/30\n",
            "269/269 [==============================] - 44s 163ms/step - loss: 0.0886 - val_loss: 0.0873\n",
            "Epoch 7/30\n",
            "269/269 [==============================] - 44s 164ms/step - loss: 0.0883 - val_loss: 0.0871\n",
            "Epoch 8/30\n",
            "269/269 [==============================] - 44s 162ms/step - loss: 0.0881 - val_loss: 0.0867\n",
            "Epoch 9/30\n",
            "269/269 [==============================] - 44s 163ms/step - loss: 0.0878 - val_loss: 0.0866\n",
            "Epoch 10/30\n",
            "269/269 [==============================] - 44s 165ms/step - loss: 0.0876 - val_loss: 0.0861\n",
            "Epoch 11/30\n",
            "269/269 [==============================] - 44s 163ms/step - loss: 0.0874 - val_loss: 0.0858\n",
            "Epoch 12/30\n",
            "269/269 [==============================] - 44s 164ms/step - loss: 0.0872 - val_loss: 0.0861\n",
            "Epoch 13/30\n",
            "269/269 [==============================] - 44s 164ms/step - loss: 0.0869 - val_loss: 0.0856\n",
            "Epoch 14/30\n",
            "269/269 [==============================] - 44s 163ms/step - loss: 0.0867 - val_loss: 0.0854\n",
            "Epoch 15/30\n",
            "269/269 [==============================] - 44s 164ms/step - loss: 0.0865 - val_loss: 0.0855\n",
            "Epoch 16/30\n",
            "269/269 [==============================] - 44s 164ms/step - loss: 0.0863 - val_loss: 0.0850\n",
            "Epoch 17/30\n",
            "269/269 [==============================] - 44s 163ms/step - loss: 0.0862 - val_loss: 0.0848\n",
            "Epoch 18/30\n",
            "269/269 [==============================] - 44s 164ms/step - loss: 0.0860 - val_loss: 0.0846\n",
            "Epoch 19/30\n",
            "269/269 [==============================] - 44s 165ms/step - loss: 0.0858 - val_loss: 0.0845\n",
            "Epoch 20/30\n",
            "269/269 [==============================] - 44s 165ms/step - loss: 0.0856 - val_loss: 0.0842\n",
            "Epoch 21/30\n",
            "269/269 [==============================] - 44s 163ms/step - loss: 0.0854 - val_loss: 0.0842\n",
            "Epoch 22/30\n",
            "269/269 [==============================] - 44s 162ms/step - loss: 0.0853 - val_loss: 0.0841\n",
            "Epoch 23/30\n",
            "269/269 [==============================] - 44s 164ms/step - loss: 0.0851 - val_loss: 0.0838\n",
            "Epoch 24/30\n",
            "269/269 [==============================] - 44s 164ms/step - loss: 0.0850 - val_loss: 0.0839\n",
            "Epoch 25/30\n",
            "269/269 [==============================] - 44s 165ms/step - loss: 0.0849 - val_loss: 0.0835\n",
            "Epoch 26/30\n",
            "269/269 [==============================] - 44s 164ms/step - loss: 0.0847 - val_loss: 0.0835\n",
            "Epoch 27/30\n",
            "269/269 [==============================] - 44s 165ms/step - loss: 0.0846 - val_loss: 0.0832\n",
            "Epoch 28/30\n",
            "269/269 [==============================] - 44s 165ms/step - loss: 0.0845 - val_loss: 0.0830\n",
            "Epoch 29/30\n",
            "269/269 [==============================] - 44s 162ms/step - loss: 0.0843 - val_loss: 0.0829\n",
            "Epoch 30/30\n",
            "269/269 [==============================] - 44s 164ms/step - loss: 0.0842 - val_loss: 0.0828\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6bc8445630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tYG3e2Huk0F"
      },
      "source": [
        "encoder_decoder.load_weights('model.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ukwy5zFZ0ept"
      },
      "source": [
        "def predict(input_sentence):\n",
        "  '''\n",
        "  A. Given input sentence, convert the sentence into integers using tokenizer used earlier\n",
        "  B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\n",
        "  C. Initialize index of <start> as input to decoder. and encoder final states as input_states to decoder\n",
        "  D. till we reach max_length of decoder or till the model predicted word <end>:\n",
        "         predicted_out,state_h,state_c=model.layers[1](dec_input,states)\n",
        "         pass the predicted_out to the dense layer\n",
        "         update the states=[state_h,state_c]\n",
        "         And get the index of the word with maximum probability of the dense layer output, using the tokenizer(word index) get the word and then store it in a string.\n",
        "         Update the input_to_decoder with current predictions\n",
        "  F. Return the predicted sentence\n",
        "  '''\n",
        "  prev_word = \"\"\n",
        "  string = \"\"\n",
        "  test_sent = input_sentence\n",
        "  test_sent_seq = tknizer_eng.texts_to_sequences([test_sent])\n",
        "  test_sent_seq = pad_sequences(test_sent_seq, maxlen=20, dtype='int32', padding='post')\n",
        "  states = encoder_decoder.encoder.get_states()\n",
        "  #print(states)\n",
        "  lstm_output,state_h,state_c = encoder_decoder.encoder(tf.convert_to_tensor(test_sent_seq),states)\n",
        "  #(1, 10119)\n",
        "  tknizer_ita.texts_to_sequences(['<start>'])\n",
        "  #decoder_out,state_dec_h,state_dec_c = encoder_decoder.decoder(tknizer_eng.texts_to_sequences(['<start>']),[state_h,state_c])\n",
        "  inp = tknizer_ita.texts_to_sequences(['<start>'])\n",
        "  inp = tf.convert_to_tensor(inp)\n",
        "  for i in range(0,20):\n",
        "    #print(i)\n",
        "    #print(inp)\n",
        "    decoder_out,state_dec_h,state_dec_c = encoder_decoder.decoder(inp,[state_h,state_c])\n",
        "    d = encoder_decoder.dense(decoder_out)\n",
        "    state_h = state_dec_h\n",
        "    state_c = state_dec_c\n",
        "    #print(d[0][0])\n",
        "    #print(ind)\n",
        "    #print()\n",
        "    ind = int(tf.math.argmax(d[0][0]))\n",
        "    word = str(tknizer_ita.sequences_to_texts([[ind]])[0])\n",
        "\n",
        "    if word == prev_word:\n",
        "      break\n",
        "    prev_word = word\n",
        "    if(word==\"<end>\"):\n",
        "      break\n",
        "    string += str(tknizer_ita.sequences_to_texts([[ind]])[0])+\" \"\n",
        "    #print(word)\n",
        "    #print(decoder_out)\n",
        "    inp = tf.convert_to_tensor(tknizer_ita.texts_to_sequences([word]))\n",
        "\n",
        "  return string[:-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqYjvuG-04cU",
        "outputId": "46c08f91-7011-4e7c-baad-25837e62525d"
      },
      "source": [
        "list_of_sentences = validation['english'].sample(10)\n",
        "for sentence in list_of_sentences:\n",
        "  print(sentence)\n",
        "  print(predict(sentence))\n",
        "  print(\"====================================================\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "she speaks chinese\n",
            "compito la con ferito\n",
            "====================================================\n",
            "i broke it\n",
            "orsetti posò informatico ferito\n",
            "====================================================\n",
            "i was upset\n",
            "ho cominci lonestà posò ferito\n",
            "====================================================\n",
            "who gave you these\n",
            "non posò ferito\n",
            "====================================================\n",
            "tom wrote love letters to mary\n",
            "compito nellesercito modesto la ferito\n",
            "====================================================\n",
            "we can not go on like this\n",
            "riscaldando informatica <start> ferito\n",
            "====================================================\n",
            "why are you crying tom\n",
            "non posò non ferito\n",
            "====================================================\n",
            "i am jittery\n",
            "compito suo compito la ferito\n",
            "====================================================\n",
            "did you do your homework by yourself\n",
            "era\n",
            "====================================================\n",
            "he promised me that he would come at four\n",
            "compito posò aiutarmi riscaldando la cugini ferito\n",
            "====================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSUZAPMa074g"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}